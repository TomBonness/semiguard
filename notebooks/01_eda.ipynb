{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECOM Dataset - EDA\n",
    "\n",
    "Quick look at the dataset before building the model. Main things to figure out:\n",
    "- How imbalanced are the classes?\n",
    "- How bad is the missing data?\n",
    "- Which features are mostly empty and should be dropped?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/uci-secom.csv')\n",
    "print(f'Shape: {df.shape}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class distribution\n",
    "\n",
    "Labels are -1 (pass) and 1 (fail). Expecting heavy imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = df['Pass/Fail'].value_counts()\n",
    "print(label_counts)\n",
    "print(f'\\nImbalance ratio: {label_counts[-1] / label_counts[1]:.1f}:1 (pass:fail)')\n",
    "\n",
    "label_counts.plot(kind='bar', color=['steelblue', 'salmon'])\n",
    "plt.title('Pass vs Fail')\n",
    "plt.xticks([0, 1], ['Pass (-1)', 'Fail (1)'], rotation=0)\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values\n",
    "\n",
    "SECOM is known for having tons of NaNs. Need to figure out which columns are mostly empty so we can drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop non-feature columns for this analysis\n",
    "features = df.drop(columns=['Time', 'Pass/Fail'])\n",
    "\n",
    "missing_pct = (features.isnull().sum() / len(features)) * 100\n",
    "print(f'Total features: {len(missing_pct)}')\n",
    "print(f'Features with any missing: {(missing_pct > 0).sum()}')\n",
    "print(f'Features with >50% missing: {(missing_pct > 50).sum()}')\n",
    "print(f'Features with zero missing: {(missing_pct == 0).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.hist(missing_pct, bins=50, edgecolor='black')\n",
    "plt.xlabel('% Missing')\n",
    "plt.ylabel('Number of Features')\n",
    "plt.title('Missing Value Distribution Across Features')\n",
    "plt.axvline(x=50, color='red', linestyle='--', label='50% threshold')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# worst offenders\n",
    "missing_pct.sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing Demo\n",
    "Showing the cleaning, scaling, and split that happens in the training pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop features with >50% missing\n",
    "threshold = 50\n",
    "cols_to_drop = missing_pct[missing_pct > threshold].index.tolist()\n",
    "df_clean = df.drop(columns=['Time'] + cols_to_drop)\n",
    "print(f\"Dropped {len(cols_to_drop)} columns with >{threshold}% missing\")\n",
    "print(f\"Remaining features: {df_clean.shape[1] - 1}\")  # minus the label column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute remaining missing values with median\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "X = df_clean.drop(columns=['Pass/Fail']).values\n",
    "y = df_clean['Pass/Fail'].values\n",
    "\n",
    "# convert labels from -1/1 to 0/1\n",
    "y = np.where(y == -1, 0, y)\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X = imputer.fit_transform(X)\n",
    "print(f\"Missing values after imputation: {np.isnan(X).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute remaining missing values with median\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "X = df_clean.drop(columns=['Pass/Fail']).values\n",
    "y = df_clean['Pass/Fail'].values\n",
    "\n",
    "# convert labels from -1/1 to 0/1\n",
    "y = np.where(y == -1, 0, y)\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X = imputer.fit_transform(X)\n",
    "print(f\"Missing values after imputation: {np.isnan(X).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(f\"Before scaling - mean: {X.mean():.2f}, std: {X.std():.2f}\")\n",
    "print(f\"After scaling  - mean: {X_scaled.mean():.4f}, std: {X_scaled.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratified train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train set: {X_train.shape[0]} samples, defect rate: {y_train.mean():.3f}\")\n",
    "print(f\"Test set:  {X_test.shape[0]} samples, defect rate: {y_test.mean():.3f}\")\n",
    "print(f\"\\nBoth ~{y.mean():.3f} - stratification preserved the ratio\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
